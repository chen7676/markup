# 机器学习

是从数据中自动分析获得规律(模型)，并利用规律对未知数据进行预测

## 学习分类

### 是否监督

- 监督学习：数据有特征、有目标值

学习过程分为：分类任务、回归任务。

分类任务的标签都是离散值，回归任务的标签都是连续值。

```
分类算法
	k-近邻算法、朴素贝叶斯、决策树、随机森林、支持向量机、逻辑回归、SVC、神经网络等

回归算法
	线型回归、岭回归、Lasson回归、SVR等
```

- 无监督学习：输入数据有特征、无目标值

任务：聚类任务、可视化任务、降维任务、异常检测、关联规则学习

聚类将数据分为不同的组别，降维用更简洁的方式表现数据。

```
聚类算法
	k-平均算法(k-Means)
	分层聚类分析(Hierarchical Cluster Analysis, HCA)
	最大期望算法(Expectation Maximization)
	
可视化和降维
	主成分分析(PCA)
	核主成分分析(Kernel PCA)
	局部线性嵌入(LLE)
	t-分步随机近邻嵌入(t-SNE)
	Isomap算法
	
关联规则学习
	Apriori
	Eclat
```

- 半监督学习：输入数据有特征部分有目标值

大多数半监督式学习算法是无监督式和监督式算法的结合。例如深度信念网络(DBN)，它基于一种互相堆叠的无监督式组件，这个组件叫做受限玻尔兹曼机(RBM)。受限玻尔兹曼机以无监督的方式进行训练，然后使用监督式学习对整个系统进行微调。

- 增强学习

它的学习系统（在其语境中称为智能体）能够观察环境，作出选择，执行操作，并获得回报，或者以负面回报的形式获得惩罚。所以它必须自行学习什么是最好的策略，从而随时间推移获得最大的回报。策略代表智能体在特定情况下应该选择的操作。

### 是否参数

参数特性主要关注存储学习参数的方式，更进一步地说是关注学习的方法。

参数模型的特征是具有固定数量的参数，而非参数模型的参数数量是无限的（由数据决定）

参数模型倾向于使用试错法，而非参数模型倾向于计数法。

非参数学习是一类参数个数以数据为基础（而不是预先定义好）的算法。这通常适用于以某种方式计数作为输入的方法，因为非参数学习能够根据数据中存在的具体项目数量相应增加参数的数量。

### 是否增量

根据系统是否可以从传入的数据流中进行增量学习分为：批量学习、在线学习

- 批量学习

批量学习中，系统无法进行增量学习，必须使用所有可用的数据进行训练，通常是离线完成的。离线学习就是先训练系统，然后将其投入生成环境，这时学习过程停止，只是将所学到的应用出来。

若是需要批量学习系统学习新数据，则需要在完整数据集的基础上重新训练一个新版本的系统，然后停用旧系统，用新系统取而代之。通常使用自动化来实现。

优点：简单

缺点：需要定时批量学习，运算量大，环境变化快时无法快速响应

- 在线学习

在在线学习中，额可以循序渐进地给系统提供训练数据，逐步积累学习成果。这种提供数据的方式可以是单独的，也可以采用小批量的小组数据来进行训练。每一步学习都很快速且便宜，所以系统可以根据飞速写入的最新数据进行学习。整个过程通常也是**离线**完成的，可将其视为增量学习。

在线学习的一个重要参数是其适应不断变化的数据的速度（即学习率）。若设置过高，则系统会迅速适应新数据，但是同时也会很快忘记旧数据；若设置过低，则系统有更高的惰性，学习会更缓慢，同时也会对新数据中的噪声或者非典型数据点的序列更不敏感。

优点：及时反映新的环境变化，适用于数据量巨大，完全无法批量学习的环境

缺点：需要加强对数据的监控，对异常数据做出响应

### 如何泛化

大多数机器学习任务是要做出预测，系统需要通过给定的训练示例，在它之前并未见过的示例上进行泛化。泛华的主要方法有：基于实例的学习、基于模型的学习

- 基于实例的学习

系统先完全记住学习的示例，然后通过某种相似度度量方式将其泛化到新的实例

```
k近邻算法
```

- 基于模型的学习

构建示例的模型，然后使用该模型进行预测
```
线性回归算法
```
## 主要挑战

### 数据方面

- 训练数据的数量不足
- 训练数据不具代表性（如采样偏差）
- 质量差的数据（如错误、异常值、噪声）
- 无关特征

解决方法

```
特征工程
```

### 算法方面

- 训练数据过拟合

解决方法

```
1.简化模型：可选择较少参数的模型，可以减少训练数据中的属性数量，或约束模型(正则化)
2.收集更多训练数据
3.减少训练数据中的噪声：如修复数据错误和消除异常值
```

- 训练数据欠拟合

解决方法

```
1.选择一个带有更多参数、更强大的模型
2.给学习算法提供更好的特征集
3.减少模型中的约束：如减少正则化超参数
```

## 相关术语

数据集

```
数据集通常被视为待处理的数据对象的合集,一般类似于一个二维的电子表格或数据库表，每行为一个样本。大部分数据集都以数据库表和数据文件的形式存在
```

数据对象

```
数据对象用于学习和评估。由于历史原因，数据对象由多个别名，如记录、点、行、向量、案例、样本、观测等
```

属性/属性值

```
数据对象也是对象，因此可用刻画对象基本特征的属性来描述。属性也有多个别名，如变量、特征、字段、维、列等
属性可以分为四种类型：标称(nominal)，序数(ordinal)，区间(interval)，比率(ratio)
标称属性的值仅仅是不同的名称，即标称值仅提供区分对象的足够信息。
序数属性的值可以提供确定对象顺序的足够信息
区间属性，比率属性的值之间的差值是有意义的，存在测量单位

标称属性和序数属性统称为分类的(categorical)或定性的(qualitative)属性，他们的取值为集合，即使用数值表示，也不具备数的大部分性质，因此，应像对待符号一样对待它们
区间属性和比率属性统称为定量的(quantitative)或数值的(numeric)属性，定量属性采用数值来表示，具备数的大部分性质，可以使用整数值或连续实数值来表示
```

标签

```
标签是指样本的目标属性，在分类问题中，每个样本都有一个标称型的类别值，在回归问题中，标签是连续型的数值
```

样本

```
训练样本用于训练机器学习算法的样本

验证样本用于调节机器学习算法参数。学习算法通常有多个参数，验证样本为这些模型参数选择适当值，使得学习算法的性能最佳

测试样本用于评估机器学习算法的性能。测试样本与训练和验证数据分离，在学习阶段不允许“偷看”测试样本
```

损失函数

```
能够度量预测标签与真实标签之间差异(或损失)的函数，它是一个非负实值函数，损失函数值越小，表示模型的鲁棒性越好
损失函数也称为代价函数，常用的损失函数有0-1损失(0-1 loss),Hinge损失(Log loss)，平方损失(squared loss)，指数损失(exponential loss)
```

假设集

```
假设集可以是一组函数，它将特征向量X映射到标签y，假设集可以是线性函数或非线性函数
```

模型

```
监督学习的目的是学一个由输入到输出的映射，称为模型
模型的集合就是假设空间
```

学习过程

```
搜索所有假设空间，与训练匹配
```

泛化能力

```
泛化能力就是机器学习算法对新样本的适应能力。
机器学习模型在训练时学习数据的本质，模型在预测学习时未见过的样本也变现良好。
```

欠拟合

```
指模型没有很好地捕捉到数据的模式，不能很好地拟合训练数据的情形。
欠拟合没有学习到训练数据的规律，在训练数据上的性能表现不好，因此需要继续学习或着更换机器学习算法
```

过拟合

```
指模型把数据学习得太彻底，甚至学习到了噪声数据的情形。
过拟合虽然非常完美滴拟合了训练数据，但不能很好地预测未知的测试数据，泛化能力太差
```

