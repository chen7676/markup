# Tensorflow

## 概述

数据模型：Tensor，计算模型：Graph，运行模型：Session

图结构：数据(tensor)+操作(operation)

安装

```python
# 注意版本号与python的对应关系
pip install tensorflow==1.8.0
```

引用

```python
import tensorflow as tf
```

一般流程

```
1.导入/生成样本数据集
2.转换和归一化数据
3.划分样本数据集为训练样本集、测试样本集和验证样本集
4.设置机器学习参数
5.初始化变量和占位符
6.定义模型结构
7.创建损失函数
8.初始化模型和训练模型
9.评估机器学习模型
10.调优超参数
11.分布/预测结果
```

## 组件

### 图

- 图操作

查看默认图

```python
a = tf.constant(2)  # tensor
b = tf.constant(3)
c = a + b  # op
# 查看默认图
# 方法一：调用方法
default_g = tf.get_default_graph()
print('default_g:', default_g)
# 方法二：查看属性
print("a的图属性：",a.graph)
print("b的图属性：",b.graph)
with tf.Session() as sess:  # 会话
    c_v = sess.run(c)
    print("c_v_res: {}". format(c_v)) 
    print("c_v的图属性：",c.graph)      
```

创建新图

```python
# 自定义图
new_g = tf.Graph()
with new_g.as_default():
    a_new = tf.constant(2)
    b_new = tf.constant(3)
    c_new = a_new + b_new
    print('c_new的图属性：', c_new.graph)
with tf.Session(graph=new_g) as new_sess:
      c_new_v = new_sess.run(c_new)
      print('c_new_v的res:{}'.format(c_new_v))
      print('new_session的图属性：', new_sess.graph)
```

- 图显示

将图序列化为本地events文件

```python
tf.summary.FileWriter('./tmp/summary/', graph=sess.graph)
```

shell启动tensorboard，在浏览器中访问`127.0.0.1:6006`

```shell
tenorboard --logdir='./tmp/summary/'
```

### 会话

一个运行TensorFlow operation的类，包含两种开启方式

```python
tf.Session  # 用于完整的程序当中
tf.InteractiveSession  # 用于交互式上下文中的Tensorflow，如shell
```

> `tf.Session`对象使用分布式Tensorflow运行时提供对本地计算机中的设备和远程设备的访问权限

- `__init__`

```python
__init__(target='', graph=None, config=None)

# 参数
- target: 如果将此参数留空，会话将仅使用本地计算机中的设备。可以指定grpc://网址，以便制定TensorFlow服务器的地址，这使得会话可以访问服务器控制的计算机上的所有设备
- graph:默认情况下，新的tf.Session将绑定当前的默认图
- config：此参数允许您指定一个tf.ConfigProto以便控制会话的行为。如ConfigProto协议用于打印设备使用信息
```

会话可能拥有的资源，如`tf.Variable`，`tf.QueueBase`和`tf.ReaderBase`。当这些资源不再需要时，需要释放这些资源。故常常使用`with`上下文管理器，等价于手动调用`tf.Session.close()`

```python
import tensorfow as tf

# with上下文
# 使用默认图
with tf.Session() as sess:
	res = sess.run(...)
    
# 使用新图
new_g = tf.Graph()
with tf.Session(graph=new_g) as new_sess:
    new_res = new_sess.run(...)
    
# 手动处理
sess = tf.Session()
...
sess.close()

# 运行会话并打印设备信息
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,
                                       log_device_placement=True))
```

会话可以分配不同的资源在不同的设备上运行

```
/job:worker/replica:0/task:0/device:CPU:0
```

- `run`

```python
run(fetches, feed_dict=None, options=None, run_metadata=None)

# 参数
- fetches:单一的operation，或者列表、元组（其他不属于tensorflow的类型不行）
- feed_dict:参数允许调用者覆盖图中张量的值，运行时赋值。与tf.placeholder搭配使用，则会检查值的形状是否与占位符兼容
```

> 使用`tf.operation.eval()`也可以运行operation，但需要在会话中运行

```python
# 创建图
a = tf.constant(5)
b = tf.constant(2)
c = a + b
# 创建会话
sess = tf.Session()
# 计算C的值,两种等价
print(sess.run(c))  # print(sess.run([a,b,c]))
print(c.eval(session=sess))
```

- `feed`

`placeholder`提供占位符，`run`的时候通过`feed_dict`指定参数

```python
imoport tensorflow as tf

data1 = tf.placeholder(tf.float32)
data2 = tf.placeholder(tf.float32)
dataAdd = tf.add(data1, data2)
with tf.Session() as sess:
  print(sess.run(dataAdd, feed_dict={data1:6, data2:2}))
print('end')
```

###张量

Tensorflow的张量就是一个n维数组，类型为`tf.Tensor`。

- 创建张量

```python
# 固定值
tf.zeros(shape, dtype=tf.float32, name=None)  # 创建所有元素为零的张量
tf.zeros_like(tensor, dtype=tf.float32, name=None)  # 创建与指定tensor相同类型和形状的所有元素为零的张量
tf.ones(shape, dtype=tf.float32, name=None)  # 创建所有元素为1的张量
tf.ones_like(tensor, dtype=None, name=None)  # 创建与指定tensor相同类型和形状的所有元素为1的张量
tf.fill(dims, value, name=None)  # 创建一个相撞为dims，并填充了标量值的张量
tf.constant(value, dtype=None, shape=None, name='Const')  # 创建一个常数张量

# 随机张量
tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)  # 从截断的正态分布中输出随机值，和tf.random()一样，但是所有数字都不会超过两个标准差
tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)  # 从正态分布中输出随机值，由随机正态分布的数字组成的矩阵

# 特殊方法
tf.Variable
tf.placeholder
```

- 张量的属性

```python
dtype	# 张量中元素的数据类型
shape	# 返回张量的数据形状 
devices # 产生张量的设备的名字
graph	# 包含张量的图
name  	# 张量的字符串名字
op		# 将张量作为输出的操作
```

- 张量的种类

constant

```python
# 常量
cosnt = tf.constant(3)  
```

variable

```python
# 值可以改变的一种张量
var1 = tf.Variable(3)
```

placeholder

```python
# 占位符
a = tf.placeholder(tf.float32, shape=(1024, 1024 ))
```

SparseTensor

```python
# 稀疏张量，类似相性代数里的稀疏矩阵
res = SparseTensor(indices=[[0, 0], [1,2]], values=[1,2], dense_shape=[3,4])
```

- Tensor的表示法

```python
Tensor("Mul:0", shape=(), dtype=float32)
类型	 名字	 索引	 形状		 数据类型
```

- 张量的数据类型

| 数据类型     | python类型   | 描述                                               |
| ------------ | ------------ | -------------------------------------------------- |
| DT_FLOAT     | tf.float32   | 32位浮点数                                         |
| DT_DOUBLE    | tf.float64   | 64位浮点数                                         |
| DT_INT64     | tf.int64     | 64位有符号整型                                     |
| DT_INT32     | tf.int32     | 32位有符号整型                                     |
| DT_INT16     | tf.int16     | 16位有符号整型                                     |
| DT_INT8      | tf.int8      | 8位有符号整型                                      |
| DT_UINT8     | tf.uint8     | 8位无符号整型                                      |
| DT_STRING    | tf.string    | 可变长度的字节数组，每一个张量元素都是一个字节数组 |
| DT_BOOL      | tf.bool      | 布尔型                                             |
| DT_COMPLEX64 | tf.complex64 | 由两个32位浮点数组成的复数：实数和虚数             |
| DT_QINT32    | tf.qint32    | 用于量化Ops的32位有符号整型                        |
| DT_QINT8     | tf.qint8     | 用于量化Ops的8位有符号整型                         |
| DT_QUINT8    | tf.quint8    | 用于量化Ops的8位无符号整型                         |

- 张量的阶

| 阶   | 数学实例 | python     | 例子                                                |
| ---- | -------- | ---------- | --------------------------------------------------- |
| 0    | 纯量     | 只有大小   | s=23                                                |
| 1    | 向量     | 大小和方向 | v =[1,2,3]                                          |
| 2    | 矩阵     | 数据表     | m=[[1,2,3],[4,5,6],[7,8,9]]                         |
| 3    | 3阶张量  | 数据立体   | t= [[[2],[4],[6]],[[8],[10],[12]],[[14],[16],[18]]] |
| n    | n阶      | ...        | ...                                                 |

示例

```python
tensor1 = tf.constant(4.0)
tensor2 = tf.constant([1,2,3,4])
linear_squares = tf.constant([[4],[9],[16],[25]], dtype=tf.int32)

print(tensor1)  # Tensor("Const:0", shape=(), dtype=float32)
print(tensor2)  # Tensor("Const_1:0", shape=(4,), dtype=int32)
print(linear_squares)  # Tensor("Const_2:0", shape=(4, 1), dtype=int32)
```
- 张量的变换

类型的改变

```python
tf.string_to_number(string_tensor, out_type=None, name=None)
tf.to_double(x, name='ToDouble')
tf.to_float(x, name='ToFloat')
tf.to_bfloat(x, name='ToBFloat16')
tf.to_int32(x, name='ToInt32')
tf.to_int64(x, name='ToInt64')
tf.cast(x, dtype, name=None)  # 原始不变，返回改变后的tensor
```

形状的改变

```python
# 动态形状
# 动态创建新张量时，元素个数必须匹配
tf.reshape(tensor,shape)  # 原始不变，返回改变后的tensor
# 静态形状
# 转换静态形状时，不能跨阶数改变形状；对于已经固定的张量的静态形状，不能再次设置静态形状
tensor.set_shape(shape)
```

- 张量的数学运算

算数运算符

基本数学函数

矩阵运算

reduce操作

序列索引操作

### 操作

一个操作对象（Operation）是TensorFlow图中的一个节点，可以接收0个或多个输入Tensor，并且可以输出0个或者多个Tensor，Operation对象是通过op构造函数(`tf.matmul()`)创建的。

```python
import tensorflow as tf
data1 = tf.constant(6)  # tf.constant是操作函数，输入int值，经过Const操作对象，输出tensor对象data1
data2 = tf.constant(2) 
dataAdd = tf.add(data1, data2)  # tf.add是操作函数，输入是tensor对象data1/data2，经过Add操作对象，输出tensor对象dataAdd
```

- 指令名称

一个图是一个命名空间，一个命名空间中指令名称不能重复；对于新的图，张量相当于重新开始，可以与其他图的指令名称相同

```python
import tensorflow as tf
data1 = tf.constant(6)
print(data1)  # Tensor("Const:0", shape=(), dtype=int32)
```

经过操作对象产生的Tensor名称的形式为`<OP_NAME>:<i>`，其中，`<OP_NAME>`是生成该张量的指令的名称；`<i>`是一个整数，表示该张量在指令的输出中的索引。

```python
# 修改指令名称
a = tf.constant(3, name='a')  # Tensor("a:0", shape=(), dtype=int32)
```

- 常见OP构造函数

| 类型           | 实例                                           |
| -------------- | ---------------------------------------------- |
| 标量运算       | add,sub,mul,div,exp,log,greater,lesse,equal    |
| 向量运算       | concat,slice,splot,constant,rank,shape,shuffle |
| 矩阵运算       | matmul,matrixinverse,matrixdateminant          |
| 带状态的运算   | variable,assgin,assginadd                      |
| 神经网络组建   | softmax,sigmod,relu,convolution,max_pool       |
| 存储，恢复     | save,restore                                   |
| 队列及同步运算 | Enqueue,Dequeue,MutexAcquire,MutexRelease      |
| 控制流         | Merge,Switch,Enter,Leave,NextIteration         |

- 示例

常量间

```python
import tensorflow as tf
data1 = tf.constant(6)
data2 = tf.constant(2)
dataAdd = tf.add(data1, data2)  # 加
dataMul = tf.multiply(data1, data2)  # 乘
dataSub = tf.subtract(data1, data2)  # 减
dataDiv = tf.divide(data1, data2) # 除
with tf.Session() as sess:
  print(
    sess.run(dataAdd),
    sess.run(dataMul),
    sess.run(dataSub),
    sess.run(dataDiv)
       )
```

常量与变量

```python
import tensorflow as tf
data1 = tf.constant(6)
data2 = tf.Variable(2)
dataAdd = tf.add(data1, data2)
dataCopy = tf.assign(data2, dataAdd)  # data2 <= dataAdd
dataMul = tf.Multiply(data1, data2)
dataSub = tf.subtract(data1, data2)
dataSiv = tf.divide(data1, data2)
init = tf.global_variables_initializer()
with tf.Session() as sess:
  sess.run(init)
  print(
  	sess.run(dataAdd),
    sess.run(dataMul),
    sess.run(dataSub),
    sess.run(dataDiv)
  )
  print('sess.run(dataCopy)', sess.run(dataCopy))  # 8
  print('dataCopy.eval()', dataCopy.eval())  # 14
  print('tf.get_default_session()', tf.get_default_session().run(dataCopy))  # 20
```

### 变量OP

tensorflow变量是表示程序处理的共享持久状态的最佳方法，变量通过`tf.Variable`OP类进行操作。变量的特点：存储持久化、可修改值、可指定被训练

- 创建变量

```python
tf.Variable(initial_value=None, trainable=True, collections=None,name=None)

# 参数
- initial_value：初始化的值
- trainable：是否被训练
- collections: 新变量将添加到列出的图的集合中collections,默认为[GraphKeys.GLOBAL._VARIABLES]，如果trainable是True变量也被添加到图形集合GraphKeys.TRAINABLE_VARIABLES
```

变量需要显式初始化，才能运行值

```python
a = tf.Variable(initial_value=50)
b = tf.Variable(initial_value=30)
c = tf.add(a, b)
print(a,b,c)
# 初始化变量
init = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init)
    a_v,b_v,c_v = sess.run([a, b, c])
    print(a_v, b_v, c_v)
```

- 修改变量的命名空间

会在OP的名字前面增加命名空间的指定名字，使得结构更加清晰

```python
with tf.variable_scope("name"):
    var = tf.Variable(name='var', initial_value=[4], dtype=tf.float32)
    var_double = tf.Variable(name='var', initial_value=[4], dtype=tf.float32)
```

## API

### 基础

| 名称           | 说明                                                         |
| -------------- | ------------------------------------------------------------ |
| `tf.app`       | 相当于为TensorFlow运行的脚本提供一个main函数入口，可以定义脚本运行的flags |
| `tf.image`     | TensorFlow的图像处理操作，主要是一些颜色变换、变形和图像的编码和解码 |
| `tf.gfile`     | 这个模块提供了一组文件操作函数                               |
| `tf.summary`   | 用来生成`TensorBoard`可用的统计日志，目前`Summary`主要提供了4中类型：`audio,image,histogram,scalar` |
| `tf.python_io` | 用来读写TFRecords文件                                        |
| `tf.train`     | 提供了一些训练器，与`tf.nn`组合起来，实现一些网络的优化计算  |
| `tf.nn`        | 提供了一些构建神经网络的底层函数。Tensrflow构建网络的核心模块。其中包含了添加各种层的函数，比如添加卷积层、池化层等 |

### 高级

| 名称           | 声明                                                         |
| -------------- | ------------------------------------------------------------ |
| `tf.keras`     | Keras是一个独立的深度学习库，增加此在于快速构建模型          |
| `tf.layers`    | 以更高级的概念层来定义一个模型。类似`tf.keras`               |
| `tf.contrib`   | 提供够将计算图中的网络层、正则化、摘要操作，是构建计算图的高级操作，但是包含不稳定和实验代码，可能后期API会改变 |
| `tf.estimator` | 相当于`Model+Training+Evaluate`，在模块中，已经实现了几种简单的分类器和回归器，包括:`Baseline,Learning,DNN`。这里`DNN`的网络，只是全连接网络，没有提供卷积之类的。 |

## 实践

- 变量显示

步骤

```
创建事件文件
收集变量
合并变量
每次迭代运行一次合并变量
每次迭代将summary对象写入事件文件
```

实现

```python
# 收集变量
tf.summary.scalar(name='', tensor)  # 收集单值变量
tf.summary.histogram(name='', tensor)  # 收集高纬度的变量参数
tf.summary.image(name='', tensor)  # 收集输入的图片张量能显示图片
# 合并变量
merged = tf.summary.merge_all()
with tf.Session() as sess:
	# 创建事件文件
	file_writer = tf.summary.FileWriter('./tmp/summary/', graph=sess.graph)
    for i in range(100):
        ...
    	# 运行合并
    	summary = sess.run(merged)  # 每次迭代都需运行
    	# 添加
    	file_writer.add_summary(summary, i)  # i表示第i此的值 
```

- 模型保存加载 

函数

```python
# 保存
tf.train.Saver(var_list=None, max_to_keep=5)
# 参数
- var_list:指定将要保存的变量，可以作为一个dict或list
- max_to_keep:指定 要保留的最近检查点文件的最大数量。创建新文件时会删除较旧的文件

# 加载
tf.train.Restore()
```

使用

```python
saver = tf.train.Saver()

# 保存模型
with tf.Session() as sess:
    for i in range(100):
        saver.save(sess, './tmp/model/my_linear.ckpt')
        
# 加载模型
with tf.Session() as sess:
    if os.path.exists('./tmp/model/checkpoint'):
        saver.restore(sess, './tmp/model/my_linear.ckpt')
```

- 命令行参数

```python
tf.app.flags
# 支持应用从命令行接受参数，可以用来指定集群配置等，在tf.app.flags下面有各种定义参数的类型：
- DEFINE_string(flag_name, default_value, docstring)
- DEFINE_integer(flag_name, default_value, docstring)
- DEFINE_boolean(flag_name, default_value, docstring)
- DEFINE_float(flag_name, default_value, docstring)

tg.apps.flags.FLAGS
# 获取命令行参数，可以调用上面定义的flag_name
```

使用

```python
# 代码
tf.app.flags.DEFINE_integer("max_step", 0, "训练模型的步数")  # 训练步数
tf.app.flags.DEFINE_string("model_dir", "", "模型保存的路径+模型的名字")  # 定义模型的路径
FLAGS = tf.app.flags.FLAGS  # 定义获取命令行参数

for i in range(FLAGS.max_step):  # 使用命令行参数
    sess.run(train_op)

def main(argv):
    print(argv)
    
if __name__=="__main__":
    tf.app.run()  # 命令行启动时自动调用main函数，传参argv
```

命令行

```
python demo.py --max_step=1
```

