# 对象识别

## SIFT特征点

**尺寸不变特征变换**(Scale Invariant Feature Transform，SIFT)是计算机视觉领域最常用的特征之一。David Lowe首次在论文中提出该特征，具体参考https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf。此后，SIFT成为图像识别和图像内容分析领域最有效的特征之一。它在大小、方向、对比度等方向都有比较强的健壮性。SIFT也是目标识别系统的基础。

```python
import sys

import cv2
import numpy as np

# Load input image -- 'table.jpg'
input_file = sys.argv[1]
img = cv2.imread(input_file)
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# 初始化SIFT检测器对象并提取关键点（指突出的点，并不是特征）
sift = cv2.xfeatures2d.SIFT_create()
keypoints = sift.detect(img_gray, None)

# 在输入图像上画出关键点
img_sift = np.copy(img)
cv2.drawKeypoints(img, keypoints, img_sift, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

cv2.imshow('Input image', img)
cv2.imshow('SIFT features', img_sift)
cv2.waitKey()

```

## Star特征

SIFT特征检测器在很多场景中都很好用，但是，当创建目标识别系统时，在用SIFT检测特征之前，可能需要用到一个不同的特征检测器，这使我们能够通过灵活地层叠不同的模块来获得最佳的性能.

```python
import sys

import cv2
import numpy as np

class StarFeatureDetector(object):
    """用于处理与Star特征检测有关的函数"""
    def __init__(self):
        self.detector = cv2.xfeatures2d.StarDetector_create()

    def detect(self, img):
        return self.detector.detect(img)

if __name__=='__main__':
    # 加载图像'table.jpg'
    input_file = sys.argv[1]
    input_img = cv2.imread(input_file)

    # 转换为灰度
    img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)

    # 用Star特征检测器检测出特征
    keypoints = StarFeatureDetector().detect(input_img)

    # 画出输入图像的关键点
    cv2.drawKeypoints(input_img, keypoints, input_img, 
            flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
    cv2.imshow('Star features', input_img)

    cv2.waitKey()

```

## 创建特征

利用视觉码本和向量量化创建特征。

为了创建一个目标识别系统，需要从每张图像中提取特征向量。每张图像需要有一个识别标志，以用于匹配。我们用一个叫**视觉码本**的概念来创建图像识别标志。在训练数据集中，这个码本基本上是一个字典，用于提出关于图像的描述。用向量化方法将很多特征点进行聚类并得出中心点。这些中心点将作为视觉码本的元素。

为创建一个健壮的目标识别系统，需要数万张图像。又一个著名的数据集Caltech256。

```python
import os
import sys
import argparse
import cPickle as pickle
import json

import cv2
import numpy as np
from sklearn.cluster import KMeans

from star_detector import StarFeatureDetector

def build_arg_parser():
    """
    对命令行进行解析
    python build_features.py --data-folder /path/to/training_images/ --codebook-file codebook.pkl --feature-map-file feature_map.pkl
    """
    parser = argparse.ArgumentParser(description='Extract features from a given \
            set of images')

    parser.add_argument("--data-folder", dest="data_folder", required=True, 
            help="Folder containing the training images organized in subfolders")
    parser.add_argument("--codebook-file", dest='codebook_file', required=True,
            help="Output file where the codebook will be stored")
    parser.add_argument("--feature-map-file", dest='feature_map_file', required=True,
            help="Output file where the feature map will be stored")
    parser.add_argument("--scaling-size", dest="scaling_size", type=int, 
            default=200, help="Scales the longer dimension of the image down \
                    to this size.")

    return parser

def load_training_data(input_folder):
    training_data = []

    if not os.path.isdir(input_folder):
        raise IOError("The folder " + input_folder + " doesn't exist")
        
    for root, dirs, files in os.walk(input_folder):
        for filename in (x for x in files if x.endswith('.jpg')):
            filepath = os.path.join(root, filename)
            object_class = filepath.split('/')[-2]
            training_data.append({'object_class': object_class, 
                'image_path': filepath})
                    
    return training_data

class FeatureBuilder(object):
    """一个提取特征的类"""
    def extract_features(self, img):
        """从输入图像提取特征"""
        # 用Star检测器获得关键点
        keypoints = StarFeatureDetector().detect(img)
        # 用SIFT提取位置的描述信息
        keypoints, feature_vectors = compute_sift_features(img, keypoints)
        return feature_vectors

    def get_codewords(self, input_map, scaling_size, max_samples=12):
        """从描述信息中提取中心点"""
        keypoints_all = []
        
        count = 0
        cur_class = ''
        # 每幅图像都会生成大量的描述信息，这里使用一小部分图像，应为这些中心点并不会发生很大的改变
        for item in input_map:
            if count >= max_samples:
                if cur_class != item['object_class']:
                    count = 0
                else:
                    continue

            count += 1

            if count == max_samples:
                print("Built centroids for", item['object_class']) 

            # 提取当前标签
            cur_class = item['object_class']
            # 读取图像并调整其大小
            img = cv2.imread(item['image_path'])
            img = resize_image(img, scaling_size)

            # 设置维度数为128并提取特征
            num_dims = 128
            feature_vectors = self.extract_features(img)
            keypoints_all.extend(feature_vectors) 

        # 用向量化来量化特征点
        kmeans, centroids = BagOfWords().cluster(keypoints_all)
        return kmeans, centroids

class BagOfWords(object):
    """处理词袋模型和向量化"""
    def __init__(self, num_clusters=32):
        self.num_dims = 128
        self.num_clusters = num_clusters
        self.num_retries = 10

    def cluster(self, datapoints):
        """量化数据点"""
        kmeans = KMeans(self.num_clusters, 
                        n_init=max(self.num_retries, 1),
                        max_iter=10, tol=1.0)
		# 提取中心点
        res = kmeans.fit(datapoints)
        centroids = res.cluster_centers_
        return kmeans, centroids

    def normalize(self, input_data):
        """归一化数据"""
        sum_input = np.sum(input_data)

        if sum_input > 0:
            return input_data / sum_input
        else:
            return input_data

    def construct_feature(self, img, kmeans, centroids):
        """获得特征向量"""
        keypoints = StarFeatureDetector().detect(img)
        keypoints, feature_vectors = compute_sift_features(img, keypoints)
        labels = kmeans.predict(feature_vectors)
        feature_vector = np.zeros(self.num_clusters)

        # 创建一个直方图并将其归一化
        for i, item in enumerate(feature_vectors):
            feature_vector[labels[i]] += 1

        feature_vector_img = np.reshape(feature_vector, 
                ((1, feature_vector.shape[0])))
        return self.normalize(feature_vector_img)

# Extract features from the input images and 
# map them to the corresponding object classes
def get_feature_map(input_map, kmeans, centroids, scaling_size):
    feature_map = []
     
    for item in input_map:
        temp_dict = {}
        temp_dict['object_class'] = item['object_class']
    
        print("Extracting features for", item['image_path']) 
        img = cv2.imread(item['image_path'])
        img = resize_image(img, scaling_size)

        temp_dict['feature_vector'] = BagOfWords().construct_feature(
                    img, kmeans, centroids)

        if temp_dict['feature_vector'] is not None:
            feature_map.append(temp_dict)

    return feature_map


def compute_sift_features(img, keypoints):
    """提取SIFT特征"""
    if img is None:
        raise TypeError('Invalid input image')

    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    keypoints, descriptors = cv2.xfeatures2d.SIFT_create().compute(img_gray, keypoints)
    return keypoints, descriptors

# Resize the shorter dimension to 'new_size' 
# while maintaining the aspect ratio
def resize_image(input_img, new_size):
    h, w = input_img.shape[:2]
    scaling_factor = new_size / float(h)

    if w < h:
        scaling_factor = new_size / float(w)

    new_shape = (int(w * scaling_factor), int(h * scaling_factor))
    return cv2.resize(input_img, new_shape) 

if __name__=='__main__':
    args = build_arg_parser().parse_args()
    data_folder = args.data_folder
    scaling_size = args.scaling_size
    
    # 加载训练数据
    training_data = load_training_data(data_folder)

    # 创建视觉码本
    print("====== Building visual codebook ======") 
    kmeans, centroids = FeatureBuilder().get_codewords(training_data, scaling_size)
    if args.codebook_file:
        with open(args.codebook_file, 'w') as f:
            pickle.dump((kmeans, centroids), f)
    
    # 从输入图片中获取特征
    print("\n====== Building the feature map ======") 
    feature_map = get_feature_map(training_data, kmeans, centroids, scaling_size)
    if args.feature_map_file:
        with open(args.feature_map_file, 'w') as f:
            pickle.dump(feature_map, f)
```

## 图像分类器

使用**极端随机森林**(Extremely Random Forest，ERF)来训练图像分类器。一个目标识别系统就是利用图像分类器将图像分到已知的类别中。ERF在机器学习领域中非常流行，因为其具有较快的速度和比较精确的准确度。基于图像的特征构建一组决策树，并通过训练这个额森林实现正确决策。

```python
import argparse 
import cPickle as pickle 

import numpy as np
from sklearn.ensemble import ExtraTreesClassifier
from sklearn import preprocessing

def build_arg_parser():
    """
    定义参数解析器
    python trainer.py --feature-map-file feature_map.pkl --model-file erf.pkl
    """
    parser = argparse.ArgumentParser(description='Trains the classifier')
    parser.add_argument("--feature-map-file", dest="feature_map_file", required=True,
            help="Input pickle file containing the feature map")
    parser.add_argument("--model-file", dest="model_file", required=False,
            help="Output file where the trained model will be stored")
    return parser

class ERFTrainer(object):
    """处理ERF训练：使用标签编码器来对训练标签进行编码"""
    def __init__(self, X, label_words):
        self.le = preprocessing.LabelEncoder()  
        self.clf = ExtraTreesClassifier(n_estimators=100, 
                max_depth=16, random_state=0)

        # 对标签编码并训练分类器
        y = self.encode_labels(label_words)
        self.clf.fit(np.asarray(X), y)

    def encode_labels(self, label_words):
        """对标签进行编码"""
        self.le.fit(label_words) 
        return np.array(self.le.transform(label_words), dtype=np.float32)

    def classify(self, X):
        """将未知数据点进行分类"""
        label_nums = self.clf.predict(np.asarray(X))
        label_words = self.le.inverse_transform([int(x) for x in label_nums]) 
        return label_words

if __name__=='__main__':
    args = build_arg_parser().parse_args()
    feature_map_file = args.feature_map_file
    model_file = args.model_file

    # 加载特征地图
    with open(feature_map_file, 'r') as f:
        feature_map = pickle.load(f)

    # 提取特征向量和标记
    label_words = [x['object_class'] for x in feature_map]
    dim_size = feature_map[0]['feature_vector'].shape[1]  
    X = [np.reshape(x['feature_vector'], (dim_size,)) for x in feature_map]
    
    # 训练ERF分类器
    erf = ERFTrainer(X, label_words) 
    # 保存模型
    if args.model_file:
        with open(args.model_file, 'w') as f:
            pickle.dump(erf, f)
```

## 对象识别器

创建一个对象识别器，可以识别未知图像的内容。

```python
import argparse 
import cPickle as pickle 

import cv2
import numpy as np

import build_features as bf
from trainer import ERFTrainer

def build_arg_parser():
    """
    命令行分析器
    python object_recognizer.py --input-image imagefile.jpg --model-file erf.pkl --codebook-file codebook.pkl
    """
    parser = argparse.ArgumentParser(description='Extracts features \
            from each line and classifies the data')
    parser.add_argument("--input-image", dest="input_image", required=True,
            help="Input image to be classified")
    parser.add_argument("--model-file", dest="model_file", required=True,
            help="Input file containing the trained model")
    parser.add_argument("--codebook-file", dest="codebook_file", 
            required=True, help="Input file containing the codebook")
    return parser

class ImageTagExtractor(object):
    """处理图像标签提取"""
    def __init__(self, model_file, codebook_file):
        with open(model_file, 'r') as f:
            self.erf = pickle.load(f)

        with open(codebook_file, 'r') as f:
            self.kmeans, self.centroids = pickle.load(f)

    def predict(self, img, scaling_size):
        """使用训练好的ERF模型预测输出"""
        img = bf.resize_image(img, scaling_size)
        feature_vector = bf.BagOfWords().construct_feature(
                img, self.kmeans, self.centroids)
        image_tag = self.erf.classify(feature_vector)[0]
        return image_tag

if __name__=='__main__':
    # 加载输入图像
    args = build_arg_parser().parse_args()
    model_file = args.model_file
    codebook_file = args.codebook_file
    input_image = cv2.imread(args.input_image)
	# 调整图像大小
    scaling_size = 200
    print("\nOutput:", ImageTagExtractor(model_file, codebook_file).predict(input_image, scaling_size)) 
```



